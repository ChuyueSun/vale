include "../../../arch/x64/X64.Vale.InsBasic.vaf"
include "../../../arch/x64/X64.Vale.InsMem.vaf"
include "../../../arch/x64/X64.Vale.InsVector.vaf"
//include "../../../arch/x64/X64.Vale.InsAes.vaf"
include "X64.AES.vaf"

module X64.GCTR

#verbatim{:interface}{:implementation}
open Types_s
open FStar.Seq
open AES_s
open X64.AES
open GCTR_s
open GCTR_i
open X64.Machine_s
open X64.Vale.State_i
open X64.Vale.Decls_i
open X64.Vale.InsBasic
open X64.Vale.InsMem
open X64.Vale.InsVector
open X64.Vale.InsAes
open X64.Vale.QuickCode_i
open X64.Vale.QuickCodes_i
//open Opaque_i
#endverbatim

//#verbatim{:interface}//{:implementation}
//
//// TODO: Annoying work around
//let index_workaround (s:seq quad32) (i:nat) =
//   if i < length s then index s i else Quad32 0 0 0 0
//
//#endverbatim

#reset-options "--z3rlimit 40"

///////////////////////////
// GCTR encryption
///////////////////////////

procedure {:quick} inc32()
    modifies 
        xmm3;
    ensures 
        xmm3 == inc32(old(xmm3), 1);
{
    assume false;
}

procedure {:quick} gctr_core(
    ghost in_b:buffer128,
    ghost out_b:buffer128,
    ghost key:aes_key(AES_128),
    ghost round_keys:seq(quad32),
    ghost keys_buffer:buffer128
    )
    lets in_ptr @= rax; out_ptr @= rbx; len @= rcx; icb @= xmm3;

    reads
        r8; in_ptr; out_ptr; len;

    modifies
        rdx; r9; r10; xmm0; xmm1; xmm2; icb; mem; efl;

    requires
        // GCTR reqs
        buffers3_disjoint128(in_b, out_b, keys_buffer);
        validSrcAddrs128(mem, in_ptr, in_b, len);
        validDstAddrs128(mem, out_ptr, out_b, len);
        in_ptr  + 16 * len < nat64_max;
        out_ptr + 16 * len < nat64_max;
        buffer_length(in_b) == buffer_length(out_b) /\ buffer_length(out_b) == len /\ 256 * buffer_length(in_b) < nat32_max;

        // AES reqs
        length(round_keys) == 11;
        round_keys == key_to_round_keys(AES_128, key);
        r8 == buffer_addr(keys_buffer);
        validSrcAddrs128(mem, r8, keys_buffer, 11);
        buffer128_as_seq(mem, keys_buffer) == round_keys;
    ensures
        modifies_buffer128(out_b, old(mem), mem);
        validSrcAddrs128(mem, out_ptr, out_b, len);
        seq_to_list(buffer128_as_seq(mem, out_b)) == gctr_encrypt(old(icb), seq_to_list(buffer128_as_seq(old(mem), in_b)), AES_128, key);
{
    Mov64(rdx, 0);
    Mov64(r9, in_ptr);
    Mov64(r10, out_ptr);

    while (rdx != len)
        invariant
            0 <= rdx <= len;
            r9 == in_ptr + 16 * rdx;
            r10 == out_ptr + 16 * rdx;
            icb == inc32(old(icb), rdx);
            
            //////////////////// From requires //////////////////////
            // GCTR reqs
            buffers3_disjoint128(in_b, out_b, keys_buffer);
            validSrcAddrs128(mem, in_ptr, in_b, len);
            validDstAddrs128(mem, out_ptr, out_b, len);
            in_ptr  + 16 * len < nat64_max;
            out_ptr + 16 * len < nat64_max;

            // AES reqs
            length(round_keys) == 11;
            round_keys == key_to_round_keys(AES_128, key);
            r8 == buffer_addr(keys_buffer);
            validSrcAddrs128(mem, r8, keys_buffer, 11);
            buffer128_as_seq(mem, keys_buffer) == round_keys;

            // Postconditions
            modifies_buffer128(out_b, old(mem), mem);
            validSrcAddrs128(mem, out_ptr, out_b, len);
            gctr_partial(rdx, buffer128_as_seq(mem, in_b), buffer128_as_seq(mem, out_b), key, old(icb));
//            forall j :: 0 <= j < rdx ==> 
//                        buffer128_read(out_b, j, mem) == 
//                        quad32_xor(index_workaround(buffer128_as_seq(mem, in_b), j), aes_encrypt(AES_128, key, inc32(old(icb), j)));

        decreases
            len - rdx;
    {
        Mov128(xmm0, icb);
        AES128EncryptBlock(icb, key, round_keys, keys_buffer);
        //assert xmm0 == aes_encrypt(AES_128, key, inc32(old(icb), rdx));   // F* believes this
        Load128_buffer(xmm1, r9, 0, in_b, rdx);
//        assert len <= length(buffer128_as_seq(mem, in_b));    // F* believes this
//        assert rdx < length(buffer128_as_seq(mem, in_b));    // F* believes this
//        assert xmm1 == index_workaround(buffer128_as_seq(mem, in_b), rdx);  // F* believes this with annoying workaround
        ghost var old_xmm1 := xmm1;
        Pxor(xmm1, xmm0);
//        assert xmm1 == quad32_xor(old_xmm1, aes_encrypt(AES_128, key, inc32(old(icb), rdx)));   // F* believes this
        Store128_buffer(r10, xmm1, 0, out_b, rdx);
//        assert buffer128_read(out_b, rdx, mem) == 
//                        quad32_xor(index_workaround(buffer128_as_seq(mem, in_b), rdx), aes_encrypt(AES_128, key, inc32(old(icb), rdx)));


        Add64(rdx, 1);
        Add64(r9, 16);
        Add64(r10, 16);
        inc32();
    }

    gctr_partial_completed(buffer128_as_seq(mem, in_b), buffer128_as_seq(mem, out_b), key, old(icb));
}

